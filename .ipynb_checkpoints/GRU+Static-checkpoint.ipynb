{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------\n",
    "# Importing Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "\n",
    "from tensorflow.keras import models, layers\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.python.client import device_lib\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from ipynb.fs.full.PreProcessing import get_moving_diff, rescaling, get_static_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 7236663841342038864\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "print(device_lib.list_local_devices())\n",
    "config = tf.ConfigProto( device_count = {'GPU': 1} ) \n",
    "sess = tf.Session(config=config) \n",
    "keras.backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------\n",
    "# Loading Data into System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_lstm_train = np.load(os.path.join('data', 'x_lstm_train.npy'))\n",
    "x_lstm_test = np.load(os.path.join('data', 'x_lstm_test.npy'))\n",
    "\n",
    "x_static_train = np.load(os.path.join('data', 'x_static_train.npy'))\n",
    "x_static_test = np.load(os.path.join('data', 'x_static_test.npy'))\n",
    "\n",
    "y_train = np.load(os.path.join('data', 'y_train.npy'))\n",
    "y_test = np.load(os.path.join('data', 'y_test.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35776, 120) (8944, 120)\n",
      "(35776, 9) (8944, 9)\n",
      "(35776, 6) (8944, 6)\n"
     ]
    }
   ],
   "source": [
    "print(x_lstm_train.shape, x_lstm_test.shape)\n",
    "print(x_static_train.shape, x_static_test.shape)\n",
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Re-Structuring the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_lstm_train = np.expand_dims(x_lstm_train, axis=-1)\n",
    "x_lstm_test = np.expand_dims(x_lstm_test, axis=-1)\n",
    "\n",
    "x_static_train = np.expand_dims(x_static_train, axis=-1)\n",
    "x_static_test = np.expand_dims(x_static_test, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35776, 120, 1) (8944, 120, 1)\n",
      "(35776, 9, 1) (8944, 9, 1)\n",
      "(35776, 6) (8944, 6)\n"
     ]
    }
   ],
   "source": [
    "print(x_lstm_train.shape, x_lstm_test.shape)\n",
    "print(x_static_train.shape, x_static_test.shape)\n",
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r_square(y_true, y_pred):\n",
    "    from keras import backend as K\n",
    "    SS_res =  K.sum(K.square(y_true - y_pred)) \n",
    "    SS_tot = K.sum(K.square(y_true - K.mean(y_true))) \n",
    "    return ( 1 - SS_res/(SS_tot + K.epsilon()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\yrvak\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\yrvak\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 120, 1)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "gru (GRU)                       [(None, 120, 120), ( 43920       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 9, 1)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 120, 120)     0           gru[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 9, 2)         4           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "gru_1 (GRU)                     [(None, 120, 120), ( 86760       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 18)           0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 258)          0           gru[0][1]                        \n",
      "                                                                 gru_1[0][1]                      \n",
      "                                                                 flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 258)          0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 64)           16576       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 64)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 16)           1040        dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 16)           0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 6)            102         dropout_3[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 148,402\n",
      "Trainable params: 148,402\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 32, 16, 30 \n",
    "model = keras.Sequential()\n",
    "\n",
    "lstm_input = layers.Input(shape=(x_lstm_train.shape[1], x_lstm_train.shape[2]))\n",
    "static_input = layers.Input(shape=(x_static_train.shape[1], x_static_train.shape[2]))\n",
    "\n",
    "lstm_stack_1, lstm_stack_1_c = layers.GRU(120, return_sequences=True, return_state=True)(lstm_input)\n",
    "drop_lstm_1 = layers.Dropout(0.05)(lstm_stack_1)\n",
    "\n",
    "lstm_stack_2, lstm_stack_2_c = layers.GRU(120, return_sequences=True, return_state=True)(drop_lstm_1)\n",
    "\n",
    "static_dense = layers.Dense(2)(static_input)\n",
    "static_flatten = layers.Flatten()(static_dense)\n",
    "\n",
    "concatenate = layers.Concatenate()([lstm_stack_1_c, lstm_stack_2_c, static_flatten])\n",
    "\n",
    "\n",
    "drop_2 = layers.Dropout(0.1)(concatenate)\n",
    "dense_1 = layers.Dense(64)(drop_2)\n",
    "drop_3 = layers.Dropout(0.05)(dense_1)\n",
    "dense_2 = layers.Dense(16)(drop_3)\n",
    "drop_4 = layers.Dropout(0.02)(dense_2)\n",
    "\n",
    "output = layers.Dense(6)(drop_4)\n",
    "\n",
    "\n",
    "model = models.Model(inputs=[lstm_input, static_input], outputs=output)\n",
    "model.summary()\n",
    "model.compile(\n",
    "    loss='mse', \n",
    "    optimizer='adam', \n",
    "    metrics=[r_square,'mae']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 35776 samples, validate on 8944 samples\n",
      "Epoch 1/5\n",
      "35760/35776 [============================>.] - ETA: 0s - loss: 0.0013 - r_square: -0.4720 - mean_absolute_error: 0.0231\n",
      "Epoch 00001: saving model to model_gru_static-001.h5\n",
      "35776/35776 [==============================] - 602s 17ms/sample - loss: 0.0013 - r_square: -0.4717 - mean_absolute_error: 0.0231 - val_loss: 6.3027e-04 - val_r_square: 0.1173 - val_mean_absolute_error: 0.0154\n",
      "Epoch 2/5\n",
      "35760/35776 [============================>.] - ETA: 0s - loss: 9.7417e-04 - r_square: 0.0036 - mean_absolute_error: 0.0183\n",
      "Epoch 00002: saving model to model_gru_static-002.h5\n",
      "35776/35776 [==============================] - 688s 19ms/sample - loss: 9.7412e-04 - r_square: 0.0039 - mean_absolute_error: 0.0183 - val_loss: 6.4118e-04 - val_r_square: 0.0959 - val_mean_absolute_error: 0.0155\n",
      "Epoch 3/5\n",
      "35760/35776 [============================>.] - ETA: 0s - loss: 9.2856e-04 - r_square: 0.0634 - mean_absolute_error: 0.0174\n",
      "Epoch 00003: saving model to model_gru_static-003.h5\n",
      "35776/35776 [==============================] - 517s 14ms/sample - loss: 9.2835e-04 - r_square: 0.0634 - mean_absolute_error: 0.0174 - val_loss: 6.2556e-04 - val_r_square: 0.1192 - val_mean_absolute_error: 0.0153\n",
      "Epoch 4/5\n",
      "35760/35776 [============================>.] - ETA: 0s - loss: 9.0746e-04 - r_square: 0.0888 - mean_absolute_error: 0.0171\n",
      "Epoch 00004: saving model to model_gru_static-004.h5\n",
      "35776/35776 [==============================] - 398s 11ms/sample - loss: 9.0732e-04 - r_square: 0.0889 - mean_absolute_error: 0.0171 - val_loss: 6.1671e-04 - val_r_square: 0.1319 - val_mean_absolute_error: 0.0152\n",
      "Epoch 5/5\n",
      "20880/35776 [================>.............] - ETA: 2:10 - loss: 8.6899e-04 - r_square: 0.1059 - mean_absolute_error: 0.0169"
     ]
    }
   ],
   "source": [
    "filepath = \"model_gru_static-{epoch:03d}.h5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='r_square', verbose=1,\n",
    "    save_best_only=False, save_weights_only=True, mode='auto', period=1)\n",
    "\n",
    "history = model.fit(\n",
    "    [x_lstm_train, x_static_train], y_train,\n",
    "    epochs=5,\n",
    "    batch_size=48,\n",
    "    verbose=1,\n",
    "    validation_data=([x_lstm_test, x_static_test], y_test),\n",
    "    shuffle=True,\n",
    "    callbacks=[checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.history.keys())\n",
    "\n",
    "fig1, (ax1, ax2) = plt.subplots(1, 2, figsize=(10,2))\n",
    "fig1.suptitle('Mean Squared Error')\n",
    "ax1.plot(history.history['loss'])\n",
    "ax2.plot(history.history['val_loss'])\n",
    "\n",
    "fig2, (ax1, ax2) = plt.subplots(1, 2, figsize=(10,2))\n",
    "fig2.suptitle('Mean Absolute Error')\n",
    "ax1.plot(history.history['mean_absolute_error'])\n",
    "ax2.plot(history.history['val_mean_absolute_error'])\n",
    "\n",
    "fig3, (ax1, ax2) = plt.subplots(1, 2, figsize=(10,2))\n",
    "fig3.suptitle('R Squared')\n",
    "ax1.plot(history.history['r_square'])\n",
    "ax2.plot(history.history['val_r_square'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(os.path.join('data','model_gru_static.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Prediction sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cgm_df = pd.read_csv(os.path.join('data','CGMData.csv')).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_data = cgm_df.T.iloc[:,-400:-1].to_numpy()\n",
    "testing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('model_gru_static-110.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = pickle.load((open(os.path.join('data','scaler.pkl'), 'rb')))\n",
    "\n",
    "time_stamps = 100\n",
    "ahead_pred = 48\n",
    "org_lstm = testing_data[:,0:time_stamps]\n",
    "y_ground = testing_data[:,time_stamps:time_stamps+ahead_pred]\n",
    "\n",
    "y_pred = []\n",
    "for i in range(ahead_pred):\n",
    "#    input_lstm = get_moving_diff(org_lstm, replace_na=True)\n",
    "    input_lstm = org_lstm\n",
    "#    input_lstm = np.vectorize(rescaling)(input_lstm)\n",
    "    \n",
    "    input_static = get_static_features(org_lstm)\n",
    "    input_static = scaler.transform(input_static)\n",
    "    \n",
    "    input_lstm = np.expand_dims(input_lstm, axis=-1)\n",
    "    input_static = np.expand_dims(input_static, axis=-1)\n",
    "\n",
    "    pred = model.predict([input_lstm, input_static])[0,0]\n",
    "#     pred = rescaling(pred[0,0], newscale=(-100,100), oldscale=(-1,1))\n",
    "#     pred = org_lstm[:,-1]+pred\n",
    "#     if pred[0] > int(pred[0])+0.5:\n",
    "#         pred[0] = int(pred[0])+1.0\n",
    "#     else:\n",
    "#         pred[0] = int(pred[0])\n",
    "        \n",
    "#     y_pred.append(pred)\n",
    "#     org_lstm = np.concatenate((org_lstm[:,1:], np.expand_dims(pred, axis=0)), axis=-1)\n",
    "\n",
    "#     pred = rescaling(org_lstm[:,-1], newscale=(0,1), oldscale=(20,450)) + pred\n",
    "#     pred = rescaling(pred, newscale=(20,450), oldscale=(0,1))\n",
    "    \n",
    "#     if pred > int(pred)+0.5:\n",
    "#         pred = int(pred)+1.0\n",
    "#     else:\n",
    "#         pred = int(pred)\n",
    "    \n",
    "#     pred = np.reshape(pred, (1,1))\n",
    "#     y_pred.append(pred)\n",
    "#     org_lstm = np.concatenate((org_lstm[:,1:], pred), axis=-1)\n",
    "\n",
    "#    pred = org_lstm[:,-1] + pred\n",
    "    \n",
    "    if pred >= int(pred)+0.5:\n",
    "        pred = int(pred)+1.0\n",
    "    else:\n",
    "        pred = int(pred)+0.0\n",
    "    \n",
    "    pred = np.reshape(pred, (1,1))\n",
    "    y_pred.append(pred)\n",
    "    org_lstm = np.concatenate((org_lstm[:,1:], pred), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = pickle.load((open(os.path.join('data','scaler.pkl'), 'rb')))\n",
    "\n",
    "time_stamps = 120\n",
    "ahead_pred = 48\n",
    "org_lstm = testing_data[:,0:time_stamps]\n",
    "y_ground = testing_data[:,time_stamps:time_stamps+ahead_pred]\n",
    "\n",
    "y_pred = []\n",
    "for i in range(ahead_pred):\n",
    "    input_lstm = get_moving_diff(org_lstm, replace_na=True)\n",
    "    input_lstm = np.vectorize(rescaling)(input_lstm)\n",
    "    \n",
    "    input_static = get_static_features(org_lstm)\n",
    "    input_static = scaler.transform(input_static)\n",
    "    \n",
    "    input_lstm = np.expand_dims(input_lstm, axis=-1)\n",
    "    input_static = np.expand_dims(input_static, axis=-1)\n",
    "\n",
    "    pred = model.predict([input_lstm, input_static])\n",
    "    \n",
    "    pred = pred[0][0]\n",
    "    pred = rescaling(pred, newscale=(-100,100), oldscale=(-1,1))\n",
    "    pred = org_lstm[:,-1]+pred\n",
    "    \n",
    "    if pred > int(pred)+0.5:\n",
    "         pred = int(pred)+1.0\n",
    "    else:\n",
    "         pred = int(pred)+0.0\n",
    "    \n",
    "    pred = np.reshape(pred, (1,1))\n",
    "    y_pred.append(pred)\n",
    "    org_lstm = np.concatenate((org_lstm[:,1:], pred), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('gru_static_good.npy',y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
