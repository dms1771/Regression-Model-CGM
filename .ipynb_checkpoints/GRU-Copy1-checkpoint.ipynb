{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------\n",
    "# Importing Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "\n",
    "from tensorflow.keras import models, layers\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.python.client import device_lib\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from ipynb.fs.full.PreProcessing import get_moving_diff, rescaling, get_static_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 10911637226693910576\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "print(device_lib.list_local_devices())\n",
    "config = tf.ConfigProto( device_count = {'GPU': 1} ) \n",
    "sess = tf.Session(config=config) \n",
    "keras.backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------\n",
    "# Loading Data into System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_lstm_train = np.load(os.path.join('data', 'x_lstm_train.npy'))\n",
    "x_lstm_test = np.load(os.path.join('data', 'x_lstm_test.npy'))\n",
    "\n",
    "x_static_train = np.load(os.path.join('data', 'x_static_train.npy'))\n",
    "x_static_test = np.load(os.path.join('data', 'x_static_test.npy'))\n",
    "\n",
    "y_train = np.load(os.path.join('data', 'y_train.npy'))\n",
    "y_test = np.load(os.path.join('data', 'y_test.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35776, 120) (8944, 120)\n",
      "(35776, 12) (8944, 12)\n",
      "(35776, 6) (8944, 6)\n"
     ]
    }
   ],
   "source": [
    "print(x_lstm_train.shape, x_lstm_test.shape)\n",
    "print(x_static_train.shape, x_static_test.shape)\n",
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Re-Structuring the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_lstm_train = np.expand_dims(x_lstm_train, axis=-1)\n",
    "x_lstm_test = np.expand_dims(x_lstm_test, axis=-1)\n",
    "\n",
    "x_static_train = np.expand_dims(x_static_train, axis=-1)\n",
    "x_static_test = np.expand_dims(x_static_test, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35776, 120, 1) (8944, 120, 1)\n",
      "(35776, 12, 1) (8944, 12, 1)\n",
      "(35776, 6) (8944, 6)\n"
     ]
    }
   ],
   "source": [
    "print(x_lstm_train.shape, x_lstm_test.shape)\n",
    "print(x_static_train.shape, x_static_test.shape)\n",
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r_square(y_true, y_pred):\n",
    "    from keras import backend as K\n",
    "    SS_res =  K.sum(K.square(y_true - y_pred)) \n",
    "    SS_tot = K.sum(K.square(y_true - K.mean(y_true))) \n",
    "    return ( 1 - SS_res/(SS_tot + K.epsilon()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 120, 1)]          0         \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  [(None, 120, 120), (None, 43920     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                7744      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 6)                 102       \n",
      "=================================================================\n",
      "Total params: 52,806\n",
      "Trainable params: 52,806\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 32, 16, 30 \n",
    "model = keras.Sequential()\n",
    "\n",
    "lstm_input = layers.Input(shape=(x_lstm_train.shape[1], x_lstm_train.shape[2]))\n",
    "\n",
    "lstm_stack_1, lstm_stack_1_c = layers.GRU(120, return_sequences=True, return_state=True)(lstm_input)\n",
    "\n",
    "drop_2 = layers.Dropout(0.1)(lstm_stack_1_c)\n",
    "dense_1 = layers.Dense(64)(drop_2)\n",
    "drop_3 = layers.Dropout(0.05)(dense_1)\n",
    "dense_2 = layers.Dense(16)(drop_3)\n",
    "drop_4 = layers.Dropout(0.05)(dense_2)\n",
    "\n",
    "output = layers.Dense(6)(drop_4)\n",
    "\n",
    "\n",
    "model = models.Model(inputs=lstm_input, outputs=output)\n",
    "model.summary()\n",
    "model.compile(\n",
    "    loss='mse', \n",
    "    optimizer='adam', \n",
    "    metrics=[r_square,'mae']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(\"model_gru_linear-{epoch:03d}.h5\", monitor='r_square', verbose=1,\n",
    "    save_best_only=False, save_weights_only=True, mode='auto', period=1)\n",
    "\n",
    "history = model.fit(\n",
    "    x_lstm_train, y_train,\n",
    "    epochs=120,\n",
    "    batch_size=48,\n",
    "    verbose=1,\n",
    "    validation_data=(x_lstm_test, y_test),\n",
    "    shuffle=True,\n",
    "    callbacks=[checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.history.keys())\n",
    "\n",
    "# Loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('mse')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train'], loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "# Loss\n",
    "plt.plot(history.history['r_square'])\n",
    "plt.title('r_square')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(os.path.join('data','model_gru_single.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Prediction sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cgm_df = pd.read_csv(os.path.join('data','CGMData.csv')).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[101.,  92.,  87.,  85.,  81.,  79.,  80.,  80.,  81.,  82.,  78.,\n",
       "         77.,  77.,  75.,  79.,  82.,  88.,  91.,  92.,  96., 101., 111.,\n",
       "        120., 126., 134., 147., 154., 158., 163., 161., 147., 131., 124.,\n",
       "        123., 124., 124., 124., 123., 124., 124., 129., 131., 128., 127.,\n",
       "        125., 127., 135., 137., 147., 147., 143., 145., 146., 146., 147.,\n",
       "        149., 150., 155., 163., 167., 169., 170., 171., 173., 180., 187.,\n",
       "        190., 182., 177., 173., 161., 153., 143., 140., 141., 139., 140.,\n",
       "        142., 130., 110., 110., 112., 117., 118., 116., 115., 114., 114.,\n",
       "        114., 114., 115., 115., 116., 117., 118., 119., 119., 120., 120.,\n",
       "        121., 121., 120., 120., 120., 122., 123., 123., 123., 122., 123.,\n",
       "        124., 125., 126., 126., 125., 124., 123., 123., 123., 122., 120.,\n",
       "        117., 116., 116., 117., 118., 118., 119., 120., 121., 122., 124.,\n",
       "        124., 124., 125., 125., 125., 125., 124., 122., 121., 119., 118.,\n",
       "        119., 123., 132., 139., 142., 144., 146., 148., 152., 156., 158.,\n",
       "        159., 159., 161., 166., 173., 181., 192., 202., 207., 208., 210.,\n",
       "        212., 217., 221., 226., 231., 235., 239., 241., 244., 241., 239.,\n",
       "        235., 228., 221., 213., 205., 199., 194., 185., 177., 171., 168.,\n",
       "        167., 161., 154., 149., 150., 153., 154., 145., 135., 127., 123.,\n",
       "        121., 121., 123., 125., 127., 127., 128., 130., 133., 133., 128.,\n",
       "        125., 120., 118., 123., 123., 118., 112.,  99.,  93.,  91.,  87.,\n",
       "         90.,  95., 100., 121., 134., 147., 156., 164., 172., 184., 199.,\n",
       "        203., 204., 205., 208., 213., 217., 213., 206., 200., 195., 193.,\n",
       "        188., 185., 181., 176., 169., 158., 151., 147., 143., 143., 147.,\n",
       "        151., 154., 153., 150., 147., 143., 140., 136., 134., 136., 135.,\n",
       "        139., 144., 150., 156., 161., 166., 170., 169., 166., 161., 156.,\n",
       "        154., 156., 159., 161., 163., 162., 163., 158., 154., 149., 146.,\n",
       "        145., 144., 141., 138., 132., 123., 116., 114., 119., 124., 124.,\n",
       "        114., 107., 105., 105., 105., 106., 108., 110., 107., 101., 101.,\n",
       "        102., 113., 115., 114., 116., 116., 120., 121., 118., 117., 117.,\n",
       "        117., 119., 114., 111., 110., 108., 109., 105., 101.,  99.,  97.,\n",
       "         97.,  98.,  98.,  97.,  97., 100.,  99.,  98.,  97.,  94.,  96.,\n",
       "         98., 100., 102., 102., 102., 105., 107., 106., 107., 109., 113.,\n",
       "        116., 118., 120., 117., 113., 112., 108., 105., 103., 104., 107.,\n",
       "        108., 105., 116., 121., 121., 125., 132., 141., 145., 143., 140.,\n",
       "        142., 144., 150., 154., 156., 157., 156., 154., 154., 156., 159.,\n",
       "        166., 169., 168., 168., 168., 164., 160., 160., 159., 178., 183.,\n",
       "        186., 189., 188., 186., 176., 172., 171., 172., 175., 176., 178.,\n",
       "        176., 171., 168., 164., 161., 159., 158., 158., 158., 155., 152.,\n",
       "        151., 150., 148., 146., 145., 145., 145., 145., 143., 138., 132.,\n",
       "        126., 123., 122., 124., 122., 115., 109., 105., 102., 103., 103.,\n",
       "        100., 100., 100., 101., 102., 101.,  98.,  95.,  91.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_data = cgm_df.T.iloc[:,-450:-1].to_numpy()\n",
    "testing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('model_gru_linear-118.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = pickle.load((open(os.path.join('data','scaler.pkl'), 'rb')))\n",
    "\n",
    "time_stamps = 100\n",
    "ahead_pred = 48\n",
    "org_lstm = testing_data[:,0:time_stamps]\n",
    "y_ground = testing_data[:,time_stamps:time_stamps+ahead_pred]\n",
    "\n",
    "y_pred = []\n",
    "for i in range(ahead_pred):\n",
    "#    input_lstm = get_moving_diff(org_lstm, replace_na=True)\n",
    "    input_lstm = org_lstm\n",
    "#    input_lstm = np.vectorize(rescaling)(input_lstm)\n",
    "    \n",
    "    input_lstm = np.expand_dims(input_lstm, axis=-1)\n",
    "    \n",
    "    pred = model.predict(input_lstm)[0,0]\n",
    "#     pred = rescaling(pred[0,0], newscale=(-100,100), oldscale=(-1,1))\n",
    "#     pred = org_lstm[:,-1]+pred\n",
    "#     if pred[0] > int(pred[0])+0.5:\n",
    "#         pred[0] = int(pred[0])+1.0\n",
    "#     else:\n",
    "#         pred[0] = int(pred[0])\n",
    "        \n",
    "#     y_pred.append(pred)\n",
    "#     org_lstm = np.concatenate((org_lstm[:,1:], np.expand_dims(pred, axis=0)), axis=-1)\n",
    "\n",
    "#     pred = rescaling(org_lstm[:,-1], newscale=(0,1), oldscale=(20,450)) + pred\n",
    "#     pred = rescaling(pred, newscale=(20,450), oldscale=(0,1))\n",
    "    \n",
    "#     if pred > int(pred)+0.5:\n",
    "#         pred = int(pred)+1.0\n",
    "#     else:\n",
    "#         pred = int(pred)\n",
    "    \n",
    "#     pred = np.reshape(pred, (1,1))\n",
    "#     y_pred.append(pred)\n",
    "#     org_lstm = np.concatenate((org_lstm[:,1:], pred), axis=-1)\n",
    "\n",
    "#    pred = org_lstm[:,-1] + pred\n",
    "    \n",
    "    if pred >= int(pred)+0.5:\n",
    "        pred = int(pred)+1.0\n",
    "    else:\n",
    "        pred = int(pred)+0.0\n",
    "    print(pred)\n",
    "    pred = np.reshape(pred, (1,1))\n",
    "    y_pred.append(pred)\n",
    "    org_lstm = np.concatenate((org_lstm[:,1:], pred), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = pickle.load((open(os.path.join('data','scaler.pkl'), 'rb')))\n",
    "\n",
    "time_stamps = 120\n",
    "ahead_pred = 48\n",
    "org_lstm = testing_data[:,0:time_stamps]\n",
    "y_ground = testing_data[:,time_stamps:time_stamps+ahead_pred]\n",
    "\n",
    "y_pred = []\n",
    "for i in range(ahead_pred):\n",
    "    input_lstm = get_moving_diff(org_lstm, replace_na=True)\n",
    "    input_lstm = np.vectorize(rescaling)(input_lstm)\n",
    "    \n",
    "    input_static = get_static_features(org_lstm)\n",
    "    input_static = scaler.transform(input_static)\n",
    "    \n",
    "    input_lstm = np.expand_dims(input_lstm, axis=-1)\n",
    "    input_static = np.expand_dims(input_static, axis=-1)\n",
    "\n",
    "    pred = model.predict(input_lstm)\n",
    "    pred=pred[0][0]\n",
    "    pred = rescaling(pred, newscale=(-100,100), oldscale=(-1,1))\n",
    "    pred = org_lstm[:,-1]+pred\n",
    "    \n",
    "    if pred >= int(pred)+0.5:\n",
    "         pred = int(pred)+1.0\n",
    "    else:\n",
    "         pred = int(pred)+0.0\n",
    "    pred = np.reshape(pred, (1,1))\n",
    "    y_pred.append(pred)\n",
    "    org_lstm = np.concatenate((org_lstm[:,1:], pred), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('gru_linear_good.npy',y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
